input {
  beats {
    port => 5044 # The port on which Logstash listens for Filebeat
  }
}

filter {

    # Assuming your GeoJSON data is the whole message
    # Parse the JSON message to get structured data
    json {
        source => "message"
    }

    # Extract the file name from the file path
    grok {
        match => { "[log][file][path]" => "/(?<filename>[^/]+)$" }
    }

    # Add or transform fields if necessary
    # For example, renaming 'message' to 'location' to match the Elasticsearch mapping
    mutate {
        rename => { "message" => "location" }
    }

    # Step 1: Remove the '.jsonl' extension
    mutate {
      gsub => ["filename", "\.jsonl$", ""]
    }
    # Step 2: Convert filename to lowercase to ensure compliance with Elasticsearch index naming conventions
    mutate {
      lowercase => ["filename"]
    }

    grok {
      match => { "filename" => "(?<name>[a-zA-Z]+)(?<year>\d{4})_bra\.tif" }
    }

    
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"] # Adjust to your Elasticsearch cluster
    index => "burned_area_index" # Custom index name
    user => "elastic" # Your Elasticsearch username
    password => "" # Your Elasticsearch password
  }
}
